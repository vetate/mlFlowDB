{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fd3fc64e-7eaf-425f-a6d8-ee6d79e8df84",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# ML Flow\n",
    "#### ML flow is an open-source platform designed to manage the entire machine learning (ML) lifecycle, from development and experimentation to deployment and monitoring\n",
    " [MLflow](https://www.mlflow.org/) is an open source platform to manage the ML lifecycle, including experimentation, reproducibility, deployment, and a central model registry.\n",
    "\n",
    "MLflow was created by Databricks, a company founded by the creators of Apache Spark. [Blog post](https://www.databricks.com/blog/2018/06/05/introducing-mlflow-an-open-source-machine-learning-platform.html)\n",
    "\n",
    "Not all elements of ML can be done in the Databricks Community Edition\n",
    "\n",
    "Check out the link from the Right side here in Experiments Runs\n",
    " \n",
    "https://docs.databricks.com/applications/mlflow/quick-start.html ---------------->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d253f92b-8864-4dfa-87bb-14ce420514e5",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### You will need to change the Databricks Enviorment from Data Science & Engineering to Machine Learning top left side"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "41470d59-9390-47ae-b295-8b39713d5add",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Create a new Cluster that is ML NOT Standard!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "972abd28-cd49-463a-ada7-b39407be886d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### https://mlflow.org/\n",
    "we will use the dataset from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5ca326c8-c3d3-420a-8a2a-3d411bf451fe",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow.sklearn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "from numpy import savetxt\n",
    " \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_diabetes\n",
    " \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5042c7ab-ad9d-45b8-bf5b-06cf7b1208fa",
     "showTitle": true,
     "title": "List the installed libraries "
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                        Version\n------------------------------ -------------\nabsl-py                        1.0.0\naccelerate                     0.23.0\naiohttp                        3.8.6\naiosignal                      1.3.1\nanyio                          3.5.0\nappdirs                        1.4.4\nargon2-cffi                    21.3.0\nargon2-cffi-bindings           21.2.0\nastor                          0.8.1\nasttokens                      2.0.5\nastunparse                     1.6.3\nasync-timeout                  4.0.3\nattrs                          22.1.0\naudioread                      3.0.1\nazure-core                     1.29.1\nazure-cosmos                   4.3.1\nazure-storage-blob             12.19.0\nazure-storage-file-datalake    12.14.0\nbackcall                       0.2.0\nbcrypt                         3.2.0\nbeautifulsoup4                 4.11.1\nblack                          22.6.0\nbleach                         4.1.0\nblinker                        1.4\nblis                           0.7.11\nboto3                          1.24.28\nbotocore                       1.27.96\ncachetools                     5.3.2\ncatalogue                      2.0.10\ncategory-encoders              2.6.2\ncertifi                        2022.12.7\ncffi                           1.15.1\nchardet                        4.0.0\ncharset-normalizer             2.0.4\nclick                          8.0.4\ncloudpathlib                   0.16.0\ncloudpickle                    2.0.0\ncmdstanpy                      1.2.0\ncomm                           0.1.2\nconfection                     0.1.3\nconfigparser                   5.2.0\ncontourpy                      1.0.5\ncryptography                   39.0.1\ncycler                         0.11.0\ncymem                          2.0.8\nCython                         0.29.32\ndacite                         1.8.1\ndatabricks-automl-runtime      0.2.20\ndatabricks-cli                 0.18.0\ndatabricks-feature-engineering 0.1.2\ndatabricks-feature-store       0.16.3\ndatabricks-sdk                 0.1.6\ndataclasses-json               0.6.2\ndatasets                       2.14.5\ndbl-tempo                      0.1.26\ndbus-python                    1.2.18\ndebugpy                        1.6.7\ndecorator                      5.1.1\ndeepspeed                      0.11.1\ndefusedxml                     0.7.1\ndill                           0.3.6\ndiskcache                      5.6.3\ndistlib                        0.3.7\ndistro                         1.7.0\ndistro-info                    1.1+ubuntu0.2\ndocstring-to-markdown          0.11\nentrypoints                    0.4\nevaluate                       0.4.1\nexecuting                      0.8.3\nfacets-overview                1.1.1\nfastjsonschema                 2.19.0\nfasttext                       0.9.2\nfilelock                       3.9.0\nFlask                          2.2.5\nflatbuffers                    23.5.26\nfonttools                      4.25.0\nfrozenlist                     1.4.0\nfsspec                         2023.6.0\nfuture                         0.18.3\ngast                           0.4.0\ngitdb                          4.0.11\nGitPython                      3.1.27\ngoogle-api-core                2.14.0\ngoogle-auth                    2.21.0\ngoogle-auth-oauthlib           1.0.0\ngoogle-cloud-core              2.3.3\ngoogle-cloud-storage           2.11.0\ngoogle-crc32c                  1.5.0\ngoogle-pasta                   0.2.0\ngoogle-resumable-media         2.6.0\ngoogleapis-common-protos       1.61.0\ngreenlet                       2.0.1\ngrpcio                         1.48.2\ngrpcio-status                  1.48.1\ngunicorn                       20.1.0\ngviz-api                       1.10.0\nh5py                           3.7.0\nhjson                          3.1.0\nholidays                       0.35\nhorovod                        0.28.1\nhtmlmin                        0.1.12\nhttplib2                       0.20.2\nhuggingface-hub                0.16.4\nidna                           3.4\nImageHash                      4.3.1\nimbalanced-learn               0.11.0\nimportlib-metadata             4.11.3\nimportlib-resources            6.1.1\nipykernel                      6.25.0\nipython                        8.14.0\nipython-genutils               0.2.0\nipywidgets                     7.7.2\nisodate                        0.6.1\nitsdangerous                   2.0.1\njedi                           0.18.1\njeepney                        0.7.1\nJinja2                         3.1.2\njmespath                       0.10.0\njoblib                         1.2.0\njoblibspark                    0.5.1\njsonpatch                      1.33\njsonpointer                    2.4\njsonschema                     4.17.3\njupyter-client                 7.3.4\njupyter_core                   5.2.0\njupyter-server                 1.23.4\njupyterlab-pygments            0.1.2\njupyterlab-widgets             1.0.0\nkeras                          2.14.0\nkeyring                        23.5.0\nkiwisolver                     1.4.4\nlangchain                      0.0.314\nlangcodes                      3.3.0\nlangsmith                      0.0.64\nlaunchpadlib                   1.10.16\nlazr.restfulclient             0.14.4\nlazr.uri                       1.0.6\nlazy_loader                    0.3\nlibclang                       15.0.6.1\nlibrosa                        0.10.1\nlightgbm                       4.1.0\nllvmlite                       0.39.1\nlxml                           4.9.1\nMako                           1.2.0\nMarkdown                       3.4.1\nMarkupSafe                     2.1.1\nmarshmallow                    3.20.1\nmatplotlib                     3.7.0\nmatplotlib-inline              0.1.6\nmccabe                         0.7.0\nmistune                        0.8.4\nml-dtypes                      0.2.0\nmlflow-skinny                  2.8.1\nmore-itertools                 8.10.0\nmpmath                         1.2.1\nmsgpack                        1.0.7\nmultidict                      6.0.4\nmultimethod                    1.10\nmultiprocess                   0.70.14\nmurmurhash                     1.0.10\nmypy-extensions                0.4.3\nnbclassic                      0.5.2\nnbclient                       0.5.13\nnbconvert                      6.5.4\nnbformat                       5.7.0\nnest-asyncio                   1.5.6\nnetworkx                       2.8.4\nninja                          1.11.1.1\nnltk                           3.7\nnodeenv                        1.8.0\nnotebook                       6.5.2\nnotebook_shim                  0.2.2\nnumba                          0.56.4\nnumpy                          1.23.5\noauthlib                       3.2.0\nopenai                         0.28.1\nopt-einsum                     3.3.0\npackaging                      22.0\npandas                         1.5.3\npandocfilters                  1.5.0\nparamiko                       2.9.2\nparso                          0.8.3\npathspec                       0.10.3\npathy                          0.10.3\npatsy                          0.5.3\npetastorm                      0.12.1\npexpect                        4.8.0\nphik                           0.12.3\npickleshare                    0.7.5\nPillow                         9.4.0\npip                            22.3.1\nplatformdirs                   2.5.2\nplotly                         5.9.0\npluggy                         1.0.0\npmdarima                       2.0.3\npooch                          1.4.0\npreshed                        3.0.9\nprometheus-client              0.14.1\nprompt-toolkit                 3.0.36\nprophet                        1.1.5\nprotobuf                       4.24.0\npsutil                         5.9.0\npsycopg2                       2.9.3\nptyprocess                     0.7.0\npure-eval                      0.2.2\npy-cpuinfo                     9.0.0\npyarrow                        8.0.0\npyarrow-hotfix                 0.5\npyasn1                         0.4.8\npyasn1-modules                 0.2.8\npybind11                       2.11.1\npycparser                      2.21\npydantic                       1.10.6\npyflakes                       3.1.0\nPygments                       2.11.2\nPyGObject                      3.42.1\nPyJWT                          2.3.0\nPyNaCl                         1.5.0\npyodbc                         4.0.32\npyparsing                      3.0.9\npyright                        1.1.294\npyrsistent                     0.18.0\npytesseract                    0.3.10\npython-apt                     2.4.0+ubuntu2\npython-dateutil                2.8.2\npython-editor                  1.0.4\npython-lsp-jsonrpc             1.1.1\npython-lsp-server              1.8.0\npytoolconfig                   1.2.5\npytz                           2022.7\nPyWavelets                     1.4.1\nPyYAML                         6.0\npyzmq                          23.2.0\nregex                          2022.7.9\nrequests                       2.28.1\nrequests-oauthlib              1.3.1\nresponses                      0.18.0\nrope                           1.7.0\nrsa                            4.9\ns3transfer                     0.6.2\nsafetensors                    0.4.0\nscikit-learn                   1.1.1\nscipy                          1.10.0\nseaborn                        0.12.2\nSecretStorage                  3.3.1\nSend2Trash                     1.8.0\nsentence-transformers          2.2.2\nsentencepiece                  0.1.99\nsetuptools                     65.6.3\nshap                           0.43.0\nsimplejson                     3.17.6\nsix                            1.16.0\nslicer                         0.0.7\nsmart-open                     5.2.1\nsmmap                          5.0.0\nsniffio                        1.2.0\nsoundfile                      0.12.1\nsoupsieve                      2.3.2.post1\nsoxr                           0.3.7\nspacy                          3.7.1\nspacy-legacy                   3.0.12\nspacy-loggers                  1.0.5\nspark-tensorflow-distributor   1.0.0\nSQLAlchemy                     1.4.39\nsqlparse                       0.4.2\nsrsly                          2.4.8\nssh-import-id                  5.11\nstack-data                     0.2.0\nstanio                         0.3.0\nstatsmodels                    0.13.5\nsympy                          1.11.1\ntabulate                       0.8.10\ntangled-up-in-unicode          0.2.0\ntenacity                       8.1.0\ntensorboard                    2.14.0\ntensorboard-data-server        0.7.2\ntensorboard-plugin-profile     2.14.0\ntensorflow-cpu                 2.14.0\ntensorflow-estimator           2.14.0\ntensorflow-io-gcs-filesystem   0.34.0\ntermcolor                      2.3.0\nterminado                      0.17.1\nthinc                          8.2.1\nthreadpoolctl                  2.2.0\ntiktoken                       0.5.1\ntinycss2                       1.2.1\ntokenize-rt                    4.2.1\ntokenizers                     0.14.0\ntomli                          2.0.1\ntorch                          2.0.1+cpu\ntorchvision                    0.15.2+cpu\ntornado                        6.1\ntqdm                           4.64.1\ntraitlets                      5.7.1\ntransformers                   4.34.0\ntypeguard                      2.13.3\ntyper                          0.9.0\ntyping_extensions              4.4.0\ntyping-inspect                 0.9.0\nujson                          5.4.0\nunattended-upgrades            0.1\nurllib3                        1.26.14\nvirtualenv                     20.16.7\nvisions                        0.7.5\nwadllib                        1.3.6\nwasabi                         1.1.2\nwcwidth                        0.2.5\nweasel                         0.3.4\nwebencodings                   0.5.1\nwebsocket-client               0.58.0\nWerkzeug                       2.2.2\nwhatthepatch                   1.0.2\nwheel                          0.38.4\nwidgetsnbextension             3.6.1\nwordcloud                      1.9.2\nwrapt                          1.14.1\nxgboost                        1.7.6\nxxhash                         3.4.1\nyapf                           0.33.0\nyarl                           1.9.2\nydata-profiling                4.2.0\nzipp                           3.11.0\n"
     ]
    }
   ],
   "source": [
    "%pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f3bb2877-22d9-4b01-8cce-48a3435c23e9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: mlflow-skinny\nVersion: 2.8.1\nSummary: MLflow: A Platform for ML Development and Productionization\nHome-page: https://mlflow.org/\nAuthor: Databricks\nAuthor-email: \nLicense: Apache License 2.0\nLocation: /databricks/python3/lib/python3.10/site-packages\nRequires: click, cloudpickle, databricks-cli, entrypoints, gitpython, importlib-metadata, packaging, protobuf, pytz, pyyaml, requests, sqlparse\nRequired-by: databricks-feature-store\n"
     ]
    }
   ],
   "source": [
    "%pip show mlflow-skinny"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "884cc245-8a18-408a-992b-9b6e21b91ca9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### MLflow Skinny: A Lightweight Machine Learning Lifecycle Platform Client\n",
    "More info in this [link](https://pypi.org/project/mlflow-skinny/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1c6ff74e-7683-44eb-9bf0-fa033f744bf8",
     "showTitle": true,
     "title": "Import the dataset from scikit-learn and create the training and test datasets."
    }
   },
   "outputs": [],
   "source": [
    "db = load_diabetes()\n",
    "x = db.data\n",
    "y = db.target\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "24eca61d-9ea9-4a1f-8585-6bb6a27571b7",
     "showTitle": true,
     "title": "Learn more about Train, Test & Split below "
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[0;31mSignature:\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0mtrain_test_split\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0marrays\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtest_size\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtrain_size\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrandom_state\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mshuffle\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstratify\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;31mSource:\u001B[0m   \n\u001B[0;32mdef\u001B[0m \u001B[0mtrain_test_split\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\u001B[0m\n\u001B[0;34m\u001B[0m    \u001B[0;34m*\u001B[0m\u001B[0marrays\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\n\u001B[0;34m\u001B[0m    \u001B[0mtest_size\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\n\u001B[0;34m\u001B[0m    \u001B[0mtrain_size\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\n\u001B[0;34m\u001B[0m    \u001B[0mrandom_state\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\n\u001B[0;34m\u001B[0m    \u001B[0mshuffle\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\n\u001B[0;34m\u001B[0m    \u001B[0mstratify\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\n\u001B[0;34m\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\n\u001B[0;34m\u001B[0m    \u001B[0;34m\"\"\"Split arrays or matrices into random train and test subsets.\u001B[0m\n\u001B[0;34m\u001B[0m\n\u001B[0;34m    Quick utility that wraps input validation and\u001B[0m\n\u001B[0;34m    ``next(ShuffleSplit().split(X, y))`` and application to input data\u001B[0m\n\u001B[0;34m    into a single call for splitting (and optionally subsampling) data in a\u001B[0m\n\u001B[0;34m    oneliner.\u001B[0m\n\u001B[0;34m\u001B[0m\n\u001B[0;34m    Read more in the :ref:`User Guide <cross_validation>`.\u001B[0m\n\u001B[0;34m\u001B[0m\n\u001B[0;34m    Parameters\u001B[0m\n\u001B[0;34m    ----------\u001B[0m\n\u001B[0;34m    *arrays : sequence of indexables with same length / shape[0]\u001B[0m\n\u001B[0;34m        Allowed inputs are lists, numpy arrays, scipy-sparse\u001B[0m\n\u001B[0;34m        matrices or pandas dataframes.\u001B[0m\n\u001B[0;34m\u001B[0m\n\u001B[0;34m    test_size : float or int, default=None\u001B[0m\n\u001B[0;34m        If float, should be between 0.0 and 1.0 and represent the proportion\u001B[0m\n\u001B[0;34m        of the dataset to include in the test split. If int, represents the\u001B[0m\n\u001B[0;34m        absolute number of test samples. If None, the value is set to the\u001B[0m\n\u001B[0;34m        complement of the train size. If ``train_size`` is also None, it will\u001B[0m\n\u001B[0;34m        be set to 0.25.\u001B[0m\n\u001B[0;34m\u001B[0m\n\u001B[0;34m    train_size : float or int, default=None\u001B[0m\n\u001B[0;34m        If float, should be between 0.0 and 1.0 and represent the\u001B[0m\n\u001B[0;34m        proportion of the dataset to include in the train split. If\u001B[0m\n\u001B[0;34m        int, represents the absolute number of train samples. If None,\u001B[0m\n\u001B[0;34m        the value is automatically set to the complement of the test size.\u001B[0m\n\u001B[0;34m\u001B[0m\n\u001B[0;34m    random_state : int, RandomState instance or None, default=None\u001B[0m\n\u001B[0;34m        Controls the shuffling applied to the data before applying the split.\u001B[0m\n\u001B[0;34m        Pass an int for reproducible output across multiple function calls.\u001B[0m\n\u001B[0;34m        See :term:`Glossary <random_state>`.\u001B[0m\n\u001B[0;34m\u001B[0m\n\u001B[0;34m    shuffle : bool, default=True\u001B[0m\n\u001B[0;34m        Whether or not to shuffle the data before splitting. If shuffle=False\u001B[0m\n\u001B[0;34m        then stratify must be None.\u001B[0m\n\u001B[0;34m\u001B[0m\n\u001B[0;34m    stratify : array-like, default=None\u001B[0m\n\u001B[0;34m        If not None, data is split in a stratified fashion, using this as\u001B[0m\n\u001B[0;34m        the class labels.\u001B[0m\n\u001B[0;34m        Read more in the :ref:`User Guide <stratification>`.\u001B[0m\n\u001B[0;34m\u001B[0m\n\u001B[0;34m    Returns\u001B[0m\n\u001B[0;34m    -------\u001B[0m\n\u001B[0;34m    splitting : list, length=2 * len(arrays)\u001B[0m\n\u001B[0;34m        List containing train-test split of inputs.\u001B[0m\n\u001B[0;34m\u001B[0m\n\u001B[0;34m        .. versionadded:: 0.16\u001B[0m\n\u001B[0;34m            If the input is sparse, the output will be a\u001B[0m\n\u001B[0;34m            ``scipy.sparse.csr_matrix``. Else, output type is the same as the\u001B[0m\n\u001B[0;34m            input type.\u001B[0m\n\u001B[0;34m\u001B[0m\n\u001B[0;34m    Examples\u001B[0m\n\u001B[0;34m    --------\u001B[0m\n\u001B[0;34m    >>> import numpy as np\u001B[0m\n\u001B[0;34m    >>> from sklearn.model_selection import train_test_split\u001B[0m\n\u001B[0;34m    >>> X, y = np.arange(10).reshape((5, 2)), range(5)\u001B[0m\n\u001B[0;34m    >>> X\u001B[0m\n\u001B[0;34m    array([[0, 1],\u001B[0m\n\u001B[0;34m           [2, 3],\u001B[0m\n\u001B[0;34m           [4, 5],\u001B[0m\n\u001B[0;34m           [6, 7],\u001B[0m\n\u001B[0;34m           [8, 9]])\u001B[0m\n\u001B[0;34m    >>> list(y)\u001B[0m\n\u001B[0;34m    [0, 1, 2, 3, 4]\u001B[0m\n\u001B[0;34m\u001B[0m\n\u001B[0;34m    >>> X_train, X_test, y_train, y_test = train_test_split(\u001B[0m\n\u001B[0;34m    ...     X, y, test_size=0.33, random_state=42)\u001B[0m\n\u001B[0;34m    ...\u001B[0m\n\u001B[0;34m    >>> X_train\u001B[0m\n\u001B[0;34m    array([[4, 5],\u001B[0m\n\u001B[0;34m           [0, 1],\u001B[0m\n\u001B[0;34m           [6, 7]])\u001B[0m\n\u001B[0;34m    >>> y_train\u001B[0m\n\u001B[0;34m    [2, 0, 3]\u001B[0m\n\u001B[0;34m    >>> X_test\u001B[0m\n\u001B[0;34m    array([[2, 3],\u001B[0m\n\u001B[0;34m           [8, 9]])\u001B[0m\n\u001B[0;34m    >>> y_test\u001B[0m\n\u001B[0;34m    [1, 4]\u001B[0m\n\u001B[0;34m\u001B[0m\n\u001B[0;34m    >>> train_test_split(y, shuffle=False)\u001B[0m\n\u001B[0;34m    [[0, 1, 2], [3, 4]]\u001B[0m\n\u001B[0;34m    \"\"\"\u001B[0m\u001B[0;34m\u001B[0m\n\u001B[0;34m\u001B[0m    \u001B[0mn_arrays\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0marrays\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\n\u001B[0;34m\u001B[0m    \u001B[0;32mif\u001B[0m \u001B[0mn_arrays\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\n\u001B[0;34m\u001B[0m        \u001B[0;32mraise\u001B[0m \u001B[0mValueError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"At least one array required as input\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\n\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\n\u001B[0;34m\u001B[0m    \u001B[0marrays\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mindexable\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0marrays\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\n\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\n\u001B[0;34m\u001B[0m    \u001B[0mn_samples\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_num_samples\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0marrays\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\n\u001B[0;34m\u001B[0m    \u001B[0mn_train\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mn_test\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_validate_shuffle_split\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\u001B[0m\n\u001B[0;34m\u001B[0m        \u001B[0mn_samples\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtest_size\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtrain_size\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdefault_test_size\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m0.25\u001B[0m\u001B[0;34m\u001B[0m\n\u001B[0;34m\u001B[0m    \u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\n\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\n\u001B[0;34m\u001B[0m    \u001B[0;32mif\u001B[0m \u001B[0mshuffle\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mFalse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\n\u001B[0;34m\u001B[0m        \u001B[0;32mif\u001B[0m \u001B[0mstratify\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\n\u001B[0;34m\u001B[0m            \u001B[0;32mraise\u001B[0m \u001B[0mValueError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\u001B[0m\n\u001B[0;34m\u001B[0m                \u001B[0;34m\"Stratified train/test split is not implemented for shuffle=False\"\u001B[0m\u001B[0;34m\u001B[0m\n\u001B[0;34m\u001B[0m            \u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\n\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\n\u001B[0;34m\u001B[0m        \u001B[0mtrain\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0marange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mn_train\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\n\u001B[0;34m\u001B[0m        \u001B[0mtest\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0marange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mn_train\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mn_train\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mn_test\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\n\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\n\u001B[0;34m\u001B[0m    \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\n\u001B[0;34m\u001B[0m        \u001B[0;32mif\u001B[0m \u001B[0mstratify\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\n\u001B[0;34m\u001B[0m            \u001B[0mCVClass\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mStratifiedShuffleSplit\u001B[0m\u001B[0;34m\u001B[0m\n\u001B[0;34m\u001B[0m        \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\n\u001B[0;34m\u001B[0m            \u001B[0mCVClass\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mShuffleSplit\u001B[0m\u001B[0;34m\u001B[0m\n\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\n\u001B[0;34m\u001B[0m        \u001B[0mcv\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mCVClass\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtest_size\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mn_test\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtrain_size\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mn_train\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrandom_state\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mrandom_state\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\n\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\n\u001B[0;34m\u001B[0m        \u001B[0mtrain\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtest\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnext\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcv\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msplit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0marrays\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mstratify\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\n\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\n\u001B[0;34m\u001B[0m    \u001B[0;32mreturn\u001B[0m \u001B[0mlist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\u001B[0m\n\u001B[0;34m\u001B[0m        \u001B[0mchain\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfrom_iterable\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\u001B[0m\n\u001B[0;34m\u001B[0m            \u001B[0;34m(\u001B[0m\u001B[0m_safe_indexing\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0ma\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtrain\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0m_safe_indexing\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0ma\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtest\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0ma\u001B[0m \u001B[0;32min\u001B[0m \u001B[0marrays\u001B[0m\u001B[0;34m\u001B[0m\n\u001B[0;34m\u001B[0m        \u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\n\u001B[0;34m\u001B[0m    \u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;31mFile:\u001B[0m      /databricks/python/lib/python3.10/site-packages/sklearn/model_selection/_split.py\n\u001B[0;31mLine:\u001B[0m      2334\n\u001B[0;31mType:\u001B[0m      function"
     ]
    }
   ],
   "source": [
    "train_test_split??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "53b1b6f2-df18-45b6-8864-4130e955f5ed",
     "showTitle": true,
     "title": "The X & Y data"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((442, 10), (442,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "03361e41-f4f9-4b0d-84b1-127282747fdb",
     "showTitle": true,
     "title": "The X and the Y"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[ 0.03807591,  0.05068012,  0.06169621, ..., -0.00259226,\n",
       "         0.01990749, -0.01764613],\n",
       "       [-0.00188202, -0.04464164, -0.05147406, ..., -0.03949338,\n",
       "        -0.06833155, -0.09220405],\n",
       "       [ 0.08529891,  0.05068012,  0.04445121, ..., -0.00259226,\n",
       "         0.00286131, -0.02593034],\n",
       "       ...,\n",
       "       [ 0.04170844,  0.05068012, -0.01590626, ..., -0.01107952,\n",
       "        -0.04688253,  0.01549073],\n",
       "       [-0.04547248, -0.04464164,  0.03906215, ...,  0.02655962,\n",
       "         0.04452873, -0.02593034],\n",
       "       [-0.04547248, -0.04464164, -0.0730303 , ..., -0.03949338,\n",
       "        -0.00422151,  0.00306441]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e68e26de-a587-46a7-a011-4580ff72a49e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([151.,  75., 141., 206., 135.,  97., 138.,  63., 110., 310., 101.,\n",
       "        69., 179., 185., 118., 171., 166., 144.,  97., 168.,  68.,  49.,\n",
       "        68., 245., 184., 202., 137.,  85., 131., 283., 129.,  59., 341.,\n",
       "        87.,  65., 102., 265., 276., 252.,  90., 100.,  55.,  61.,  92.,\n",
       "       259.,  53., 190., 142.,  75., 142., 155., 225.,  59., 104., 182.,\n",
       "       128.,  52.,  37., 170., 170.,  61., 144.,  52., 128.,  71., 163.,\n",
       "       150.,  97., 160., 178.,  48., 270., 202., 111.,  85.,  42., 170.,\n",
       "       200., 252., 113., 143.,  51.,  52., 210.,  65., 141.,  55., 134.,\n",
       "        42., 111.,  98., 164.,  48.,  96.,  90., 162., 150., 279.,  92.,\n",
       "        83., 128., 102., 302., 198.,  95.,  53., 134., 144., 232.,  81.,\n",
       "       104.,  59., 246., 297., 258., 229., 275., 281., 179., 200., 200.,\n",
       "       173., 180.,  84., 121., 161.,  99., 109., 115., 268., 274., 158.,\n",
       "       107.,  83., 103., 272.,  85., 280., 336., 281., 118., 317., 235.,\n",
       "        60., 174., 259., 178., 128.,  96., 126., 288.,  88., 292.,  71.,\n",
       "       197., 186.,  25.,  84.,  96., 195.,  53., 217., 172., 131., 214.,\n",
       "        59.,  70., 220., 268., 152.,  47.,  74., 295., 101., 151., 127.,\n",
       "       237., 225.,  81., 151., 107.,  64., 138., 185., 265., 101., 137.,\n",
       "       143., 141.,  79., 292., 178.,  91., 116.,  86., 122.,  72., 129.,\n",
       "       142.,  90., 158.,  39., 196., 222., 277.,  99., 196., 202., 155.,\n",
       "        77., 191.,  70.,  73.,  49.,  65., 263., 248., 296., 214., 185.,\n",
       "        78.,  93., 252., 150.,  77., 208.,  77., 108., 160.,  53., 220.,\n",
       "       154., 259.,  90., 246., 124.,  67.,  72., 257., 262., 275., 177.,\n",
       "        71.,  47., 187., 125.,  78.,  51., 258., 215., 303., 243.,  91.,\n",
       "       150., 310., 153., 346.,  63.,  89.,  50.,  39., 103., 308., 116.,\n",
       "       145.,  74.,  45., 115., 264.,  87., 202., 127., 182., 241.,  66.,\n",
       "        94., 283.,  64., 102., 200., 265.,  94., 230., 181., 156., 233.,\n",
       "        60., 219.,  80.,  68., 332., 248.,  84., 200.,  55.,  85.,  89.,\n",
       "        31., 129.,  83., 275.,  65., 198., 236., 253., 124.,  44., 172.,\n",
       "       114., 142., 109., 180., 144., 163., 147.,  97., 220., 190., 109.,\n",
       "       191., 122., 230., 242., 248., 249., 192., 131., 237.,  78., 135.,\n",
       "       244., 199., 270., 164.,  72.,  96., 306.,  91., 214.,  95., 216.,\n",
       "       263., 178., 113., 200., 139., 139.,  88., 148.,  88., 243.,  71.,\n",
       "        77., 109., 272.,  60.,  54., 221.,  90., 311., 281., 182., 321.,\n",
       "        58., 262., 206., 233., 242., 123., 167.,  63., 197.,  71., 168.,\n",
       "       140., 217., 121., 235., 245.,  40.,  52., 104., 132.,  88.,  69.,\n",
       "       219.,  72., 201., 110.,  51., 277.,  63., 118.,  69., 273., 258.,\n",
       "        43., 198., 242., 232., 175.,  93., 168., 275., 293., 281.,  72.,\n",
       "       140., 189., 181., 209., 136., 261., 113., 131., 174., 257.,  55.,\n",
       "        84.,  42., 146., 212., 233.,  91., 111., 152., 120.,  67., 310.,\n",
       "        94., 183.,  66., 173.,  72.,  49.,  64.,  48., 178., 104., 132.,\n",
       "       220.,  57.])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ff4ae67c-a1d3-4e3c-9b13-de5a313ad420",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Create a random forest model and log parameters\n",
    "[MLFlow Python API](https://mlflow.org/docs/latest/python_api/index.html)\n",
    "\n",
    "[Quickstart Guide Outside Databricks](https://mlflow.org/docs/latest/quickstart.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "81c4baef-6da3-4c97-93cc-86d0e86710be",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mlflow.sklearn.autolog()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "83a7a679-b48f-43ed-8d78-a5f6a9d6f83a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Look at your Experiments Runs to the Right as you run the code below ---------------------------->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8c963d92-7c1a-4463-a5e8-a7a84fd05254",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/01/27 20:07:34 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/databricks/python/lib/python3.10/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\"\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc2d44db64f649eb9b8de521f3fa98eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# With autolog() enabled, all model parameters, a model score, and the fitted model are automatically logged.  \n",
    "with mlflow.start_run():\n",
    "  \n",
    "  # Set the model parameters. \n",
    "  n_estimators = 100\n",
    "  max_depth = 6\n",
    "  max_features = 3\n",
    "  \n",
    "  # Create and train model.\n",
    "  rf = RandomForestRegressor(n_estimators = n_estimators, max_depth = max_depth, max_features = max_features)\n",
    "  rf.fit(X_train, y_train)\n",
    "  \n",
    "  # Use the model to make predictions on the test dataset.\n",
    "  predictions = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4748c75b-76a6-4d80-9af1-82fa571adb53",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Now go to Experiment UI from link to the Right in Experiment Runs ----------------->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3531ce42-424c-4803-8ce2-ae53a4e02759",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Classification problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6e1356fb-75ef-4a68-97f0-3cb21120de6e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "916029ce-74d7-4224-80b9-32cd9945b24f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "28602e1c-fa74-41f7-a728-9e52216418bd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# To ignore all warnings, you can use the following line:\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "78cfdda2-68b5-4e18-bd82-d2ed7094bc9c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## What is Numpy?\n",
    "\"numpy\" This is the name of the library being imported. NumPy is a powerful library for numerical computing and array manipulation in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "799000a0-b7ee-4ec0-be25-f73ca9cf82ee",
     "showTitle": true,
     "title": "Load another DataSet "
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6dd9b301-d42c-4b8f-9caf-6243583f6f86",
     "showTitle": true,
     "title": "Load Iris dataset"
    }
   },
   "outputs": [],
   "source": [
    "# Load a dataset (in this case, the Iris dataset for simplicity)\n",
    "data = load_iris()\n",
    "X = data.data\n",
    "y = data.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ef5a7ad1-76bb-4fb5-aeef-a5f7d309c775",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Split the dataset into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "035b7669-a1a3-4128-a66c-f064772d1f54",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "000eee8e-d08c-45ff-b201-01301db1fd49",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Name your Experiment Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b717b4d5-6a9f-4c3e-b9ef-15b6559d4eed",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/python/lib/python3.10/site-packages/sklearn/neighbors/_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n/databricks/python/lib/python3.10/site-packages/sklearn/neighbors/_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa6ad57f744846f8afec410263d0c9c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/python/lib/python3.10/site-packages/sklearn/neighbors/_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n/databricks/python/lib/python3.10/site-packages/sklearn/neighbors/_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d44885201eed4ee1b3511d6a615ac01f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/python/lib/python3.10/site-packages/sklearn/neighbors/_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run(run_name=\"classifier\"):\n",
    "    # Create a classifier (in this case, K-Nearest Neighbors)\n",
    "    clf = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "    # Train the classifier on the training data\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    y_pred = clf.predict(X_test)\n",
    "    warnings.filterwarnings('ignore')"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "DB 05 ML Flow Notebook",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
